{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a13604b-ba59-4a5c-a556-e4567b9130b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b391eb86-3890-4da2-be94-39a439e819b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdaf6945-8ac9-438f-b23a-57c67e8eea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str\n",
    "\n",
    "@tool\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    return Command(update=state_update)\n",
    "\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert(len(message.tool_calls) <= 1)\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c80ac9-39be-4823-a334-3e8e82f2ebc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (b59272f2-1053-42e5-a381-6ab57f730223)\n",
      " Call ID: b59272f2-1053-42e5-a381-6ab57f730223\n",
      "  Args:\n",
      "    query: when was LangGraph released\n",
      "    topic: general\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"when was LangGraph released\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"Langgraph — Part 1 of LLM Multi-Agents series - Medium\", \"url\": \"https://medium.com/mitb-for-all/a-gentle-introduction-to-the-llm-multi-agents-multiverse-part-1-langgraph-2ac56f1b5b3c\", \"content\": \"Langgraph — Part 1 of LLM Multi-Agents series | by Tituslhy | MITB For All | Medium Langgraph — Part 1 of LLM Multi-Agents series Langgraph was released in January 2024 (“this year” at the time of writing) by the creators of LangChain, aiming to empower developers to build stateful, reliable multi-agent applications extending the capabilities of the LangChain framework. Just as the ecosystem of LLM orchestration libraries often takes LangChain as a reference point, the multi-agent systems landscape frequently looks to Langgraph, building their frameworks on similar core principles. However, Langgraph’s steep learning curve means developers should be prepared to write more code and spend additional time debugging Langgraph objects, especially with intricate multi-agent systems.\", \"score\": 0.8803145, \"raw_content\": null}, {\"title\": \"Releases · langchain-ai/langgraph - GitHub\", \"url\": \"https://github.com/langchain-ai/langgraph/releases\", \"content\": \"Releases · langchain-ai/langgraph GitHub Copilot Write better code with AI GitHub Advanced Security Find and fix vulnerabilities Code Search Find more, search less *   Why GitHub *   GitHub Advanced Security Enterprise-grade security features Search code, repositories, users, issues, pull requests... Releases: langchain-ai/langgraph Releases · langchain-ai/langgraph github-actions github-actions [docs] LangGraph / LangGraph Platform docs updates (#4479) Add clear cache methods github-actions Changes since checkpoint==2.0.25 checkpoint: release 2.0.26 (#4708) docs(reference): filter class methods and add missing docstrings (#4463) github-actions Update python SDK docstrings (#4602) github-actions github-actions feat: CLI: Add main.py (#4637) github-actions github-actions fix for langgraph docstring fixes for libs/langgraph docs: update add_messages API ref (#4495) github-actions Release checkpoint-sqlite (#4509) docstrings for checkpoint-sqlite Add delete_thread method to Checkpointer class (#4328) github-actions\", \"score\": 0.3238295, \"raw_content\": null}], \"response_time\": 2.27}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph was released in January 2024.\n",
      "Tool Calls:\n",
      "  human_assistance (f40a29a6-2d31-445b-ba64-479aaa141d9f)\n",
      " Call ID: f40a29a6-2d31-445b-ba64-479aaa141d9f\n",
      "  Args:\n",
      "    birthday: January 2024\n",
      "    name: LangGraph Release Date\n"
     ]
    }
   ],
   "source": [
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e077a40-6cad-4cec-a7e9-51634078213d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Message dict must contain 'role' and 'content' keys, got {'parts': [{'text': \"I'm learning LangGraph. Could you do some research on it for me?\"}], 'role': 'user'}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/MESSAGE_COERCION_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agenticai/lib/python3.13/site-packages/langchain_core/messages/utils.py:333\u001b[39m, in \u001b[36m_convert_to_message\u001b[39m\u001b[34m(message)\u001b[39m\n\u001b[32m    332\u001b[39m     \u001b[38;5;66;03m# None msg content is not allowed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     msg_content = msg_kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyError\u001b[39m: 'content'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m      2\u001b[39m events = graph.stream(\n\u001b[32m      3\u001b[39m     {\n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [{\u001b[33m\"\u001b[39m\u001b[33mparts\u001b[39m\u001b[33m\"\u001b[39m:[{\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mI\u001b[39m\u001b[33m'\u001b[39m\u001b[33mm learning LangGraph. Could you do some research on it for me?\u001b[39m\u001b[33m\"\u001b[39m}],\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m}],\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     stream_mode=\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m event:\n\u001b[32m     11\u001b[39m         event[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].pretty_print()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agenticai/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2524\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2518\u001b[39m     get_waiter = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m   2519\u001b[39m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2520\u001b[39m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2521\u001b[39m \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2522\u001b[39m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2523\u001b[39m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2524\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m   2525\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2526\u001b[39m         loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agenticai/lib/python3.13/site-packages/langgraph/pregel/loop.py:494\u001b[39m, in \u001b[36mPregelLoop.tick\u001b[39m\u001b[34m(self, input_keys)\u001b[39m\n\u001b[32m    484\u001b[39m     print_step_writes(\n\u001b[32m    485\u001b[39m         \u001b[38;5;28mself\u001b[39m.step,\n\u001b[32m    486\u001b[39m         writes,\n\u001b[32m   (...)\u001b[39m\u001b[32m    491\u001b[39m         ),\n\u001b[32m    492\u001b[39m     )\n\u001b[32m    493\u001b[39m \u001b[38;5;66;03m# all tasks have finished\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m mv_writes, updated_channels = apply_writes(\n\u001b[32m    495\u001b[39m     \u001b[38;5;28mself\u001b[39m.checkpoint,\n\u001b[32m    496\u001b[39m     \u001b[38;5;28mself\u001b[39m.channels,\n\u001b[32m    497\u001b[39m     \u001b[38;5;28mself\u001b[39m.tasks.values(),\n\u001b[32m    498\u001b[39m     \u001b[38;5;28mself\u001b[39m.checkpointer_get_next_version,\n\u001b[32m    499\u001b[39m     \u001b[38;5;28mself\u001b[39m.trigger_to_nodes,\n\u001b[32m    500\u001b[39m )\n\u001b[32m    501\u001b[39m \u001b[38;5;66;03m# apply writes to managed values\u001b[39;00m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m mv_writes.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agenticai/lib/python3.13/site-packages/langgraph/pregel/algo.py:322\u001b[39m, in \u001b[36mapply_writes\u001b[39m\u001b[34m(checkpoint, channels, tasks, get_next_version, trigger_to_nodes)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chan, vals \u001b[38;5;129;01min\u001b[39;00m pending_writes_by_channel.items():\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m channels[chan].update(vals) \u001b[38;5;129;01mand\u001b[39;00m get_next_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    323\u001b[39m             checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m][chan] = get_next_version(\n\u001b[32m    324\u001b[39m                 max_version,\n\u001b[32m    325\u001b[39m                 channels[chan],\n\u001b[32m    326\u001b[39m             )\n\u001b[32m    327\u001b[39m             \u001b[38;5;66;03m# unavailable channels can't trigger tasks, so don't add them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agenticai/lib/python3.13/site-packages/langgraph/channels/binop.py:91\u001b[39m, in \u001b[36mBinaryOperatorAggregate.update\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m     89\u001b[39m     values = values[\u001b[32m1\u001b[39m:]\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m values:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28mself\u001b[39m.value = \u001b[38;5;28mself\u001b[39m.operator(\u001b[38;5;28mself\u001b[39m.value, value)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agenticai/lib/python3.13/site-packages/langgraph/graph/message.py:38\u001b[39m, in \u001b[36m_add_messages_wrapper.<locals>._add_messages\u001b[39m\u001b[34m(left, right, **kwargs)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_add_messages\u001b[39m(\n\u001b[32m     35\u001b[39m     left: Optional[Messages] = \u001b[38;5;28;01mNone\u001b[39;00m, right: Optional[Messages] = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any\n\u001b[32m     36\u001b[39m ) -> Union[Messages, Callable[[Messages, Messages], Messages]]:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(left, right, **kwargs)\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     40\u001b[39m         msg = (\n\u001b[32m     41\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMust specify non-null arguments for both \u001b[39m\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mright\u001b[39m\u001b[33m'\u001b[39m\u001b[33m. Only \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreceived: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mleft\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mright\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agenticai/lib/python3.13/site-packages/langgraph/graph/message.py:181\u001b[39m, in \u001b[36madd_messages\u001b[39m\u001b[34m(left, right, format)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# coerce to message\u001b[39;00m\n\u001b[32m    175\u001b[39m left = [\n\u001b[32m    176\u001b[39m     message_chunk_to_message(cast(BaseMessageChunk, m))\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m convert_to_messages(left)\n\u001b[32m    178\u001b[39m ]\n\u001b[32m    179\u001b[39m right = [\n\u001b[32m    180\u001b[39m     message_chunk_to_message(cast(BaseMessageChunk, m))\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m convert_to_messages(right)\n\u001b[32m    182\u001b[39m ]\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# assign missing ids\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m left:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agenticai/lib/python3.13/site-packages/langchain_core/messages/utils.py:367\u001b[39m, in \u001b[36mconvert_to_messages\u001b[39m\u001b[34m(messages)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(messages, PromptValue):\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m messages.to_messages()\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [_convert_to_message(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m messages]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agenticai/lib/python3.13/site-packages/langchain_core/messages/utils.py:339\u001b[39m, in \u001b[36m_convert_to_message\u001b[39m\u001b[34m(message)\u001b[39m\n\u001b[32m    335\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMessage dict must contain \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keys, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    336\u001b[39m         msg = create_message(\n\u001b[32m    337\u001b[39m             message=msg, error_code=ErrorCode.MESSAGE_COERCION_FAILURE\n\u001b[32m    338\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    340\u001b[39m     _message = _create_message_from_message_type(\n\u001b[32m    341\u001b[39m         msg_type, msg_content, **msg_kwargs\n\u001b[32m    342\u001b[39m     )\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Message dict must contain 'role' and 'content' keys, got {'parts': [{'text': \"I'm learning LangGraph. Could you do some research on it for me?\"}], 'role': 'user'}\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/MESSAGE_COERCION_FAILURE "
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [{\"parts\":[{\"text\":\"I'm learning LangGraph. Could you do some research on it for me?\"}],\"role\":\"user\"}],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d0cbd1-2c74-49a2-9603-5f849476cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Here: https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/chatbots/information-gather-prompting.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
